% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/beta_hat.R
\name{beta_hat_svd}
\alias{beta_hat_svd}
\title{Beta-hat - Singular Value Decomposition}
\usage{
beta_hat_svd(X, y)
}
\arguments{
\item{X}{Matrix.
The data matrix
\eqn{\mathbf{X}}
is an \eqn{n \times k} matrix
of \eqn{n} observations
of \eqn{k} regressors,
which includes a regressor
whose value is 1 for each observation.}

\item{y}{Vector or \code{n} by \code{1} matrix.
The vector
\eqn{\mathbf{y}}
is an \eqn{n \times 1} vector
of observations on the regressand variable.}
}
\value{
Returns \eqn{\boldsymbol{\hat{\beta}}}
that is,
a \eqn{k \times 1} vector of estimates
of \eqn{k} unknown regression coefficients
estimated using ordinary least squares.
}
\description{
Estimates coefficients of a linear regression model
using the Singular Value Decomposition.
The data matrix (\eqn{\mathbf{X}}) is decomposed into
\deqn{
    \mathbf{X}
    =
    \mathbf{U}
    \mathbf{\Sigma}
    \mathbf{V}^{\prime}.
  }
Estimates are found by solving
\deqn{
    \boldsymbol{\hat{\beta}}
    =
    \mathbf{V}
    \mathbf{\Sigma}^{+}
    \mathbf{U}^{\prime}
    \mathbf{y}
  }
where the superscript \eqn{+} indicates the pseudoinverse.
}
\references{
\href{https://en.wikipedia.org/wiki/Linear_regression}{Wikipedia: Linear Regression}

\href{https://en.wikipedia.org/wiki/Ordinary_least_squares}{Wikipedia: Ordinary Least Squares}

\href{https://en.wikipedia.org/wiki/Singular_value_decomposition}{Wikipedia: Singular Value Decomposition}

\href{https://en.wikipedia.org/wiki/Numerical_methods_for_linear_least_squares#Orthogonal_decomposition_methods}{Wikipedia: Orthogonal decomposition methods}
}
\seealso{
Other beta-hat functions: 
\code{\link{beta_hat_inv}()},
\code{\link{beta_hat_qr}()}
}
\concept{beta-hat functions}
