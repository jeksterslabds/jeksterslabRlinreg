% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sehat.R
\name{.sehatslopeshatprimetb}
\alias{.sehatslopeshatprimetb}
\title{Standard Errors of Standardized Estimates of Regression Coefficients (Textbook)}
\usage{
.sehatslopeshatprimetb(
  slopeshat = NULL,
  sehatslopeshat = NULL,
  slopeshatprime = NULL,
  X,
  y
)
}
\arguments{
\item{slopeshat}{Numeric vector of length \code{p} or \code{p} by \code{1} matrix.
\eqn{p \times 1} column vector of estimated regression slopes \eqn{\left( \boldsymbol{\hat{\beta}}_{2, 3, \cdots, k} = \left\{ \hat{\beta}_2, \hat{\beta}_3, \cdots, \hat{\beta}_k \right\}^{T} \right)} .}

\item{sehatslopeshat}{Numeric vector of length \code{p} or \code{p} by \code{1} matrix.
\eqn{p \times 1} column vector of estimated standard errors of estimates of regression slopes
\eqn{\left( \mathbf{\widehat{se}}_{\boldsymbol{\hat{\beta}}_{2, 3, \cdots, k}^{\prime}} = \left\{ \mathrm{\hat{se}}_{\hat{\beta}_{2}^{\prime}}, \mathrm{\hat{se}}_{\hat{\beta}_{3}^{\prime}}, \cdots, \mathrm{\hat{se}}_{\hat{\beta}_{k}^{\prime}} \right\}^{T} \right)} .}

\item{slopeshatprime}{Numeric vector of length \code{p} or \code{p} by \code{1} matrix.
\eqn{p \times 1} column vector of estimated standardized regression slopes
\eqn{\left( \boldsymbol{\hat{\beta}}_{2, 3, \cdots, k}  = \left\{ \hat{\beta}_2, \hat{\beta}_3, \cdots, \hat{\beta}_k \right\}^{T} \right)} .}

\item{X}{\code{n} by \code{k} numeric matrix.
The data matrix \eqn{\mathbf{X}}
(also known as design matrix, model matrix or regressor matrix)
is an \eqn{n \times k} matrix of \eqn{n} observations of \eqn{k} regressors,
which includes a regressor whose value is 1 for each observation on the first column.}

\item{y}{Numeric vector of length \code{n} or \code{n} by \code{1} matrix.
The vector \eqn{\mathbf{y}} is an \eqn{n \times 1} vector of observations
on the regressand variable.}
}
\description{
Standard Errors of Standardized Estimates of Regression Coefficients (Textbook)
}
\details{
\deqn{
    \mathbf{\widehat{se}}_{\boldsymbol{\hat{\beta}}_{2, \cdots, k}^{\prime}} =
    \mathbf{\widehat{se}}_{\boldsymbol{\hat{\beta}}_{2, \cdots, k}} \frac{\boldsymbol{\hat{\beta}}_{2, \cdots, k}^{\prime}}{\boldsymbol{\hat{\beta}}_{2, \cdots, k}}
  }
According to Yuan and Chan (2011), this standard error is biased.
}
\references{
Yuan, K., Chan, W. (2011).
Biases and Standard Errors of Standardized Regression Coefficients.
\emph{Psychometrika} 76, 670-690.
\href{https://doi.org/10.1007/s11336-011-9224-6}{doi:10.1007/s11336-011-9224-6}.
}
\seealso{
Other standard errors of estimates of regression coefficients functions: 
\code{\link{.sehatbetahatbiased}()},
\code{\link{.sehatbetahat}()},
\code{\link{.sehatslopeshatprimedelta}()},
\code{\link{sehatbetahatbiased}()},
\code{\link{sehatbetahat}()},
\code{\link{sehatslopeshatprimedelta}()},
\code{\link{sehatslopeshatprimetb}()}
}
\author{
Ivan Jacob Agaloos Pesigan
}
\concept{standard errors of estimates of regression coefficients functions}
\keyword{se}
