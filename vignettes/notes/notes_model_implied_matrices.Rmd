---
title: "Notes: Model-Implied Matrices"
author: "Ivan Jacob Agaloos Pesigan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Notes: Model-Implied Matrices}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Path Diagram

```{tikz, linear_regression, echo = FALSE, fig.width = 4, fig.height = 4,fig.cap = "Linear Regression Model", fig.ext = "png", cache = TRUE}
\usetikzlibrary{er, arrows, positioning}
\begin{tikzpicture}[
  auto,
  node distance = 25mm,
  manifest/.style = {
    rectangle,
    draw,
    thick,
    inner sep = 0pt,
    minimum width = 15mm,
    minimum height = 10mm
  },
  inv/.style = {
    rectangle,
    draw=none,
    fill=none,
    inner sep = 0pt,
    minimum width = 15mm,
    minimum height = 10mm
  },
  error/.style = {
    ellipse,
    draw,
    thick,
    inner sep = 0pt,
    minimum size = 7mm,
    align = center
  },
  mean/.style={
    regular polygon,
    regular polygon sides = 3,
    draw,
    thick,
    inner sep = 0pt,
    minimum width = 15mm,
    minimum height = 10mm
  },
  path/.style = {
    ->,
    thick,
    >=stealth'
  },
  cov/.style = {
    <->,
    thick,
    >=stealth'
  },
]
  \node[mean] (1) {$1$};
  \node[manifest] (X2) [below = of 1] {$X_2$};
  \node[manifest] (X3) [below = of X2] {$X_3$};
  \node[manifest] (Xdots) [below = of X3] {$\vdots$};
  \node[manifest] (Xk) [below = of Xdots] {$X_k$};
  \node[manifest] (Y) [left = of X3] {$Y$};
  \node[error] (epsilon) [below = of Y] {$\varepsilon$};
  \draw [path] (1) to node {$\beta_1$} (Y);
  \draw [path] (X2) to node {$\beta_2$} (Y);
  \draw [path] (X3) to node {$\beta_3$} (Y);
  \draw [path] (Xdots) to node {$\vdots$} (Y);
  \draw [path] (Xk) to node {$\beta_k$} (Y);
  \draw [path] (epsilon) to node {1} (Y);
  \draw [path] (1) to[out=360,in=360] node[right] {$\mu_{X_{2}}$} (X2);
  \draw [path] (1) to[out=360,in=360] node[right] {$\mu_{X_{3}}$} (X3);
  \draw [path] (1) to[out=360,in=360] node[right] {$\mu_{X_{\dots}}$} (Xdots);
  \draw [path] (1) to[out=360,in=360] node[right] {$\mu_{X_{k}}$} (Xk);
  \draw [cov] (1) to[out=70,in=110,looseness=5] node[above] {1} (1);
  \draw [cov] (epsilon) to[out=-60,in=-120,looseness=7] node[below] {$\sigma^{2}$} (epsilon);
  \draw [cov] (X2) to[out=70,in=110,looseness=5] node[above] {$\sigma^{2}_{X_{2}}$} (X2);
  \draw [cov] (X3) to[out=70,in=110,looseness=5] node[above] {$\sigma^{2}_{X_{3}}$} (X3);
  \draw [cov] (Xdots) to[out=70,in=110,looseness=5] node[above] {$\sigma^{2}_{X_{\dots}}$} (Xdots);
  \draw [cov] (Xk) to[out=70,in=110,looseness=5] node[above] {$\sigma^{2}_{X_{k}}$} (Xk);
  \draw [cov] (X2) to[out=360, in=360] node[left] {$\sigma_{X_{2}, X_{3}}$} (X3);
  \draw [cov] (X3) to[out=360, in=360] node[left] {$\sigma_{X_{3}, X_{\dots}}$} (Xdots);
  \draw [cov] (Xdots) to[out=360, in=360] node[left] {$\sigma_{X_{\dots}, X_{4}}$} (Xk);
  \draw [cov] (X2) to[out=360,in=360] node[left] {$\sigma_{X_{2}, X_{\dots}}$} (Xdots);
  \draw [cov] (X2) to[out=360,in=360] node[right] {$\sigma_{X_{2}, X_{k}}$} (Xk);
  \draw [cov] (X3) to[out=360,in=360] node[left] {$\sigma_{X_{3}, X_{k}}$} (Xk);
\end{tikzpicture}
```

## Model-Implied Variance Covariance Matrix

The parameters of a linear regression model
for the covariance structure
are
the slopes
($\boldsymbol{\beta}_{\mathrm{slopes}}$),
the variance of the error term $\boldsymbol{\varepsilon}$
($\sigma^2$),
and
the variances and covariances of
${X}_{2}, {X}_{3}, \dots, {X}_{k}$
($\boldsymbol{\Sigma}_{\mathbf{X}}$).

The parameters form the following matrices,

\begin{equation}
  \mathbf{A}
  =
  \begin{bmatrix}
    0 & \beta_2 & \beta_3 & \cdots & \beta_k \\
    0 & 0       & 0       & \cdots & 0       \\
    0 & 0       & 0       & \cdots & 0       \\
    0 & 0       & 0       & \cdots & 0       \\
    0 & 0       & 0       & \cdots & 0
  \end{bmatrix} ,
\end{equation}

\begin{equation}
  \mathbf{S}
  =
  \begin{bmatrix}
    \sigma^2 & 0                         & 0                         & \cdots & 0                         \\
    0        & \mathrm{Var}_{X_2}        & \mathrm{Cov}_{X_{2}X_{3}} & \cdots & \mathrm{Cov}_{X_{2}X_{k}} \\
    0        & \mathrm{Cov}_{X_{3}X_{2}} & \mathrm{Var}_{X_3}        & \cdots & \mathrm{Cov}_{X_{3}X_{k}} \\
    0        & \vdots                    & \vdots                    & \ddots & \vdots                    \\
    0        & \mathrm{Cov}_{X_{k}X_{2}} & \mathrm{Cov}_{X_{k}X_{3}} & \cdots & \mathrm{Var}_{X_k}
  \end{bmatrix} ,
\end{equation}

\begin{equation}
  \mathbf{I}
  =
  \begin{bmatrix}
    1 & 0   & 0   & \cdots & 0   \\
    0 & 1   & 0   & \cdots & 0   \\
    0 & 0   & 1   & \cdots & 0   \\
    0 & 0   & 0   & 1      & 0   \\
    0 & 0   & 0   & \cdots & 1
  \end{bmatrix} ,
\end{equation}

\noindent and

\begin{equation}
  \mathbf{F}
  =
  \begin{bmatrix}
    1 & 0   & 0   & \cdots & 0   \\
    0 & 1   & 0   & \cdots & 0   \\
    0 & 0   & 1   & \cdots & 0   \\
    0 & 0   & 0   & 1      & 0   \\
    0 & 0   & 0   & \cdots & 1
  \end{bmatrix} .
\end{equation}

The model-implied variance-covariance matrix
($\boldsymbol{\Sigma} \left( \boldsymbol{\theta} \right)$)
is calculated using

\begin{equation}
  \boldsymbol{\Sigma}
  \left(
    \boldsymbol{\theta}
  \right)
  =
  \mathbf{F}
  \left(
    \mathbf{I} - \mathbf{A}
  \right)^{-1}
  \mathbf{S}
  \left[
    \left(
      \mathbf{I} - \mathbf{A}
    \right)^{-1}
  \right]^{\prime}
  \mathbf{F}^{\prime} .
\end{equation}
